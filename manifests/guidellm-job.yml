apiVersion: batch/v1
kind: Job
metadata:
  generateName: guidellm-{{.JobName}}-
  namespace: llm-d-scale
spec:
  completionMode: NonIndexed
  completions: {{ .completions }}
  parallelism: {{ .parallelism}}
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: guidellm
        volumeMounts:
        - name: results
          mountPath: /results
        env:
        {{ range $k, $v := .env }}
          - name: {{ $k }}
            value: "{{ $v }}"
        {{ end }}
          - name: HF_HOME # Required to avoid permissions issues when downloading the tokenizer and creating the cache directory
            value: /results
        image: {{ .image }}
        command: ["/bin/sh", "-c"]
        args:
        - |
          guidellm benchmark run && \                          # TODO: optimize model downloading
          benchmark_parser.py benchmarks.json {{ .UUID }} \
          --es-server={{ .ES_SERVER }} \
          --es-index={{ .ES_INDEX }} \
          --job-name={{ .JobName }} &&
          sleep {{ .pause }}
      volumes:
      - name: results
        emptyDir: {}

