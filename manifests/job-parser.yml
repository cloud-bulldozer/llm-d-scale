apiVersion: batch/v1
kind: Job
metadata:
  generateName: guidellm
  namespace: llm-d-scale
spec:
  completionMode: NonIndexed
  completions: 1
  backoffLimit: 0
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: guidellm
        volumeMounts:
        - name: results
          mountPath: /results
        env:
          - name: GUIDELLM_TARGET
            value: http://10.32.160.89:8000
          - name: HF_HOME # Required to avoid permissions issues when downloading the tokenizer and creating the cache directory
            value: /results
          - name: GUIDELLM_DATA
            value: "prompt_tokens=512,output_tokens=512"
          - name: GUIDELLM_MAX_SECONDS
            value: "10"
          - name: GUIDELLM_RATE_TYPE
            value: "constant"
          - name: GUIDELLM_RATE
            value: "10"
        command: ["/bin/sh", "-c"]
        args:
        - |
          guidellm benchmark run && benchmark_parser.py benchmarks.json e9ba5463-f56a-4438-927e-c784a0a2c275
        image: quay.io/rsevilla/guidellm-parser:latest
      volumes:
      - name: results
        emptyDir: {}

