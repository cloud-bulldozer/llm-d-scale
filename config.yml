---
{{ $model := "Qwen/Qwen3-0.6B" }}
{{ $samples := 3 }}
{{ $guidellmImage := "quay.io/rsevilla/guidellm-parser:latest" }}
{{ $guidellmES :=  .ES_SERVER }}
{{ $guidellmESIndex := .ES_INDEX }}
{{ $guidellmParallelism := 1 }}

metricsEndpoints:
  - metrics: [metrics.yml]
    step: 15s                           # Using step 15s provides more granularity
    indexer:
      esServers: ["{{ $guidellmES }}"]
      defaultIndex: "{{ $guidellmESIndex }}"
      type: "opensearch"
      insecureSkipVerify: true
global:
  gc: true
jobs:
  - name: deploy-infra
    namespace: llm-d-scale
    namespacedIterations: false
    preLoadImages: false
    cleanup: false
    verifyObjects: false
    qps: 5
    burst: 5
    objects:
      - objectTemplate: manifests/gateway.yml
      - objectTemplate: manifests/gateway-cm.yml
        inputVars:
          replicas: 1
      - objectTemplate: manifests/destinationrule.yml
      - objectTemplate: manifests/epp-service.yml
      - objectTemplate: manifests/epp-config.yml
      - objectTemplate: manifests/epp-sa.yml
      - objectTemplate: manifests/epp-clusterrole.yml
      - objectTemplate: manifests/epp-clusterrolebinding.yml        
      - objectTemplate: manifests/epp-deployment.yml
        inputVars:
          configFile: config/default.yaml
          image: ghcr.io/llm-d/llm-d-inference-scheduler:v0.2.1
          replicas: 1
      - objectTemplate: manifests/inferencepool.yml
      - objectTemplate: manifests/httproute.yml
      - objectTemplate: manifests/hf-token.yml
      - objectTemplate: manifests/sim-config.yml
        inputVars:
          model: {{ $model }}
          maxModelLen: 65536                  # Max lenght of the model, including the input and output tokens
          ttft: 0
          itl: 0
      - objectTemplate: manifests/model-server-sim-deployment.yml
        inputVars:
          replicas: 2
      
  - name: steady-chat
    preLoadImages: false
    qps: 5
    burst: 5
    objects:
      - objectTemplate: manifests/guidellm-job.yml
        inputVars:
          pause: 30s
          parallelism: {{ $guidellmParallelism }}
          completions: {{ $samples }}
          env:
            GUIDELLM_TARGET: "http://llm-d-scale-istio.llm-d-scale.svc.cluster.local"
            GUIDELLM_MAX_SECONDS: "120"
            GUIDELLM_RATE_TYPE: constant
            GUIDELLM_RATE: "10"
            GUIDELLM_DATA: "prompt_tokens=256,output_tokens=256"
          image: {{ $guidellmImage }}
          ES_SERVER: {{ $guidellmES }}
          ES_INDEX: {{ $guidellmESIndex }}

  - name: steady-rag
    preLoadImages: false
    qps: 5
    burst: 5
    objects:
      - objectTemplate: manifests/guidellm-job.yml
        inputVars:
          pause: 10s
          parallelism: {{ $guidellmParallelism }}
          completions: {{ $samples }}
          env:
            GUIDELLM_TARGET: "http://llm-d-scale-istio.llm-d-scale.svc.cluster.local"
            GUIDELLM_MAX_SECONDS: "120"
            GUIDELLM_RATE_TYPE: constant
            GUIDELLM_RATE: "10"
            GUIDELLM_DATA: "prompt_tokens=8192,output_tokens=512"
          image: {{ $guidellmImage }}
          ES_SERVER: {{ $guidellmES }}
          ES_INDEX: {{ $guidellmESIndex }}

  - name: throughput-chat
    preLoadImages: false
    qps: 5
    burst: 5
    objects:
      - objectTemplate: manifests/guidellm-job.yml
        inputVars:
          pause: 10s
          parallelism: {{ $guidellmParallelism }}
          completions: {{ $samples }}
          env:
            GUIDELLM_TARGET: "http://llm-d-scale-istio.llm-d-scale.svc.cluster.local"
            GUIDELLM_MAX_SECONDS: "120"
            GUIDELLM_RATE_TYPE: throughput
            GUIDELLM_DATA: "prompt_tokens=256,output_tokens=256"
          image: {{ $guidellmImage }}
          ES_SERVER: {{ $guidellmES }}
          ES_INDEX: {{ $guidellmESIndex }}

  - name: throughput-rag
    preLoadImages: false
    qps: 5
    burst: 5
    objects:
      - objectTemplate: manifests/guidellm-job.yml
        inputVars:
          pause: 10s
          parallelism: {{ $guidellmParallelism }}
          completions: {{ $samples }}
          env:
            GUIDELLM_TARGET: "http://llm-d-scale-istio.llm-d-scale.svc.cluster.local"
            GUIDELLM_MAX_SECONDS: "120"
            GUIDELLM_RATE_TYPE: throughput
            GUIDELLM_DATA: "prompt_tokens=8192,output_tokens=512"
          image: {{ $guidellmImage }}
          ES_SERVER: {{ $guidellmES }}
          ES_INDEX: {{ $guidellmESIndex }}
